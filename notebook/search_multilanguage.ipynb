{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852864b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.ai.inference.aio import EmbeddingsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from models.resolution import Resolution\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from dataclasses import asdict\n",
    "from openai import AsyncAzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from typing import List\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f52b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "search_endpoint = os.getenv('SEARCH_ENDPOINT')\n",
    "search_api_key = os.getenv('SEARCH_API_KEY')\n",
    "\n",
    "endpoint=os.getenv('AI_FOUNDRY_OPENAI_ENDPOINT')\n",
    "api_key = os.getenv('OPENAI_KEY')\n",
    "chat_model = os.getenv('OPEN_AI_CHAT_MODEL')\n",
    "\n",
    "cohere_key = os.getenv('COHERE_KEY')\n",
    "cohere_model=os.getenv('COHERE_MODEL')\n",
    "cohere_endpoint=os.getenv('COHERE_ENDPOINT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f96d45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = EmbeddingsClient(\n",
    "    endpoint=cohere_endpoint,\n",
    "    credential=AzureKeyCredential(cohere_key)\n",
    ")\n",
    "model_name = cohere_model    \n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=\"cartroubleshooting\",\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")    \n",
    "\n",
    "chat_client = AsyncAzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await chat_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am going to Paris, what should I see?\",\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4096,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    model=chat_model\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55ba1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_instruction = \"\"\"You are a helpful car troubleshooting assistant. Your role is to help users find resolutions to car problems in multiple languages.\n",
    "\n",
    "You will be provided with relevant troubleshooting information retrieved from a database based on the user's question. This information is included below:\n",
    "\n",
    "{context}\n",
    "\n",
    "Your responsibilities:\n",
    "\n",
    "1. DETECT the language of the user's question and remember it for your response.\n",
    "\n",
    "2. CRITICAL - Language Handling:\n",
    "   - ALWAYS respond to the user in the SAME language they used in their question\n",
    "   - Supported languages include: English, Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, Korean, Arabic, and many others\n",
    "   - Even if the provided troubleshooting information is in a different language, translate your response to match the user's language\n",
    "   - Keep the technical terms (brand, model) as provided, but translate your explanations and instructions to the user's language\n",
    "\n",
    "3. Present the troubleshooting solutions ONLY using the information provided in the context above. You MUST NOT add any additional troubleshooting advice, suggestions, or information that is not explicitly provided in the context.\n",
    "\n",
    "4. The provided context contains Resolution information with:\n",
    "   - id: The resolution ID\n",
    "   - score: Relevance score (higher is better match)\n",
    "   - brand: Car brand\n",
    "   - model: Car model\n",
    "   - fault: Description of the fault\n",
    "   - fix: How to fix the issue\n",
    "\n",
    "5. Format your response based ONLY on the data provided in the context:\n",
    "   - Present each solution clearly with the car brand and model\n",
    "   - Show the fault description (translated to user's language if needed)\n",
    "   - Provide the fix instructions (translated to user's language if needed)\n",
    "   - You may mention the relevance score to help users understand how well it matches their problem\n",
    "   - Do NOT supplement with general automotive knowledge\n",
    "   - Do NOT make assumptions or add information not present in the provided context\n",
    "\n",
    "6. Keep responses concise and practical:\n",
    "   - Focus on the specific fixes provided\n",
    "   - Present all solutions provided in the context (typically top 3 matches)\n",
    "   - End with encouraging words in the user's language such as:\n",
    "     * English: \"Try these fixes and see if they resolve your issue\"\n",
    "     * Spanish: \"Prueba estas soluciones y verifica si resuelven tu problema\"\n",
    "     * French: \"Essayez ces solutions et voyez si elles résolvent votre problème\"\n",
    "     * (Adapt to other languages as needed)\n",
    "\n",
    "7. If the context is empty or contains no troubleshooting information, politely inform the user in their language that no matching solutions were found for their problem.\n",
    "\n",
    "Remember:\n",
    "- ALWAYS respond in the SAME language the user used in their question\n",
    "- ONLY present information that is provided in the context\n",
    "- Keep the tone friendly and helpful while staying factual to the provided data\n",
    "- If the user's query is completely unrelated to car problems, politely explain in their language that you can only help with car troubleshooting issues\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77790369",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_answer_from_model(prompt:str, context:List[Resolution]) -> str:\n",
    "    resolutions_json = json.dumps([asdict(res) for res in context], indent=2)\n",
    "    system_msg = template_instruction.replace('{context}',resolutions_json)\n",
    "    response = await chat_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_msg\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=4096,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        model=chat_model\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7d113",
   "metadata": {},
   "source": [
    "Create the plugin to get embedding from the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cf13ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def embed( prompt:str) -> List[Resolution]:\n",
    "    \"\"\"\n",
    "    Get the vector embedding representation of a text prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt to convert into a vector embedding\n",
    "        \n",
    "    Returns:\n",
    "        List[Resolution]: A list of Resolution objects containing the top matching\n",
    "                         troubleshooting solutions, including car brand, model,\n",
    "                         fault description, and fix instructions\n",
    "    \"\"\"\n",
    "    response = await embedding_client.embed(input=[prompt],\n",
    "                                            model=cohere_model)\n",
    "    \n",
    "    vector = response.data[0]['embedding']\n",
    "\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=vector,\n",
    "        k_nearest_neighbors=3,\n",
    "        fields=\"vector\"\n",
    "    )\n",
    "\n",
    "    results = await search_client.search(\n",
    "        search_text=\"\",\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\",\"brand\",\"model\",\"fault\",\"fix\"]                \n",
    "    )\n",
    "\n",
    "    resolutions:List[Resolution] = []\n",
    "    #resolutions = []\n",
    "    async for result in results:\n",
    "        #resolutions.append(result)\n",
    "        resolutions.append(Resolution(\n",
    "            id=result['id'],\n",
    "            score=result['@search.score'],\n",
    "            brand=result['brand'],\n",
    "            model=result['model'],\n",
    "            fault=result['fault'],\n",
    "            fix=result['fix']\n",
    "        ))\n",
    "\n",
    "    return resolutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8cbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await embed(\"Battery draining fast\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f21128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Mon moteur est beaucoup trop chaud\"\n",
    "\n",
    "context = await embed(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9308cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
