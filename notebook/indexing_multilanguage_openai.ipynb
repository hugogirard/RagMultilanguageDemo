{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8c4cb1",
   "metadata": {},
   "source": [
    "# 🌐 Multilingual Document Indexing with OpenAI Embeddings\n",
    "\n",
    "## 📌 Important Note\n",
    "This notebook demonstrates a **simplified approach** to document indexing using **OpenAI's text-embedding-3-large model**. While OpenAI embeddings support multilingual text, they work best when:\n",
    "- 📝 Documents are in **major languages** (English, Spanish, French, German, etc.)\n",
    "- 🔄 You want to use the **same embedding model** for both indexing and search\n",
    "- ⚡ You need a **quick setup** without complex language detection\n",
    "\n",
    "## 📊 Workflow Overview\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    A[📁 Multilingual Excel File] --> B[📋 Convert to JSON]\n",
    "    B --> C[🤖 Generate OpenAI Embeddings]\n",
    "    C --> D[🔍 Upload to Azure AI Search]\n",
    "    \n",
    "    style A fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff\n",
    "    style C fill:#9013FE,stroke:#6A0DAD,stroke-width:2px,color:#fff\n",
    "    style D fill:#50E3C2,stroke:#2ECC71,stroke-width:2px,color:#000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from openai import AsyncAzureOpenAI\n",
    "import json\n",
    "import os\n",
    "import asyncio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e548f",
   "metadata": {},
   "source": [
    "## 📦 Setup: Import Libraries and Initialize Clients\n",
    "\n",
    "This section imports all necessary libraries for the indexing pipeline:\n",
    "- 🔐 **Azure Authentication**: DefaultAzureCredential for secure access\n",
    "- 🤖 **OpenAI**: AsyncAzureOpenAI for generating embeddings\n",
    "- 🔍 **Azure Cognitive Search**: SearchClient for document indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1646ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "open_ai_endpoint = os.getenv('OPENAI_ENDPOINT')\n",
    "open_ai_key = os.getenv('OPENAI_KEY')\n",
    "open_ai_embedding_model = os.getenv('EMBEDDING_OPENAI_DEPLOYMENT')\n",
    "\n",
    "# Search\n",
    "search_endpoint = os.getenv('SEARCH_ENDPOINT')\n",
    "search_api_key = os.getenv('SEARCH_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8073a5",
   "metadata": {},
   "source": [
    "## ⚙️ Configuration: Load Environment Variables\n",
    "\n",
    "Load all required API keys and endpoints from the `.env` file:\n",
    "- 🤖 **OpenAI endpoint and key**: For generating embeddings with text-embedding-3-large\n",
    "- 📐 **Embedding model deployment**: The specific OpenAI embedding model to use\n",
    "- 🔍 **Azure Cognitive Search credentials**: For uploading and indexing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53cc27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_credential = DefaultAzureCredential()\n",
    "\n",
    "openai = AsyncAzureOpenAI(\n",
    "    azure_endpoint=open_ai_endpoint,\n",
    "    api_key=open_ai_key,\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")\n",
    "\n",
    "index_name=\"multi_language_openai\"\n",
    "\n",
    "credential = AzureKeyCredential(search_api_key)\n",
    "\n",
    "search_client = SearchClient(endpoint=search_endpoint,\n",
    "                             index_name=index_name,\n",
    "                             credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c1bba",
   "metadata": {},
   "source": [
    "## 🛠️ Helper Functions\n",
    "\n",
    "### 📋 CSV/Excel to JSON Converter\n",
    "\n",
    "The `csv_to_json_array()` function converts tabular data to JSON format:\n",
    "- ✅ Supports both **CSV** and **Excel** files (.xlsx, .xls)\n",
    "- 🔄 Converts column names from \"Title Case\" to \"snake_case\"\n",
    "- 🧹 Replaces NaN values with empty strings\n",
    "- 💾 Saves the result as a JSON array file\n",
    "\n",
    "This function is essential for preparing data before embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cee2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_json_array(csv_file:str, output_file:str):\n",
    "    \"\"\"Convert CSV or Excel file to array of JSON objects with snake_case field names\"\"\"\n",
    "    \n",
    "    # Check file extension and read accordingly\n",
    "    if csv_file.endswith('.xlsx') or csv_file.endswith('.xls'):\n",
    "        # Read Excel file into DataFrame\n",
    "        df = pd.read_excel(csv_file)\n",
    "    else:\n",
    "        # Read CSV file into DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Replace NaN values with empty strings\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    # Convert column names from \"Title Case\" to \"snake_case\"\n",
    "    def to_snake_case(name):\n",
    "        # Replace spaces with underscores and convert to lowercase\n",
    "        return name.replace(' ', '_').lower()\n",
    "    \n",
    "    # Rename all columns to snake_case\n",
    "    df.columns = [to_snake_case(col) for col in df.columns]\n",
    "    \n",
    "    # Convert DataFrame to list of dictionaries (JSON objects)\n",
    "    data = df.to_dict(orient='records')\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Converted {len(data)} records from {csv_file} to JSON array\")\n",
    "    print(f\"Converted column names: {list(df.columns)}\")\n",
    "    print(\"\\nFirst record example:\")\n",
    "    print(json.dumps(data[0], indent=2))\n",
    "    \n",
    "    # Save JSON array to file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\nJSON array saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439dbb53",
   "metadata": {},
   "source": [
    "## 📄 Step 1: Convert Excel to JSON\n",
    "\n",
    "Convert the multilingual car problems Excel file to JSON format:\n",
    "- 📥 **Input**: `car_problems_multilingual.xlsx` - Excel file with car problems in multiple languages\n",
    "- 📤 **Output**: `car_problems_multilingual.json` - JSON array with snake_case field names\n",
    "\n",
    "This step prepares the data structure for embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_json_array(csv_file=\"car_problems_multilingual.xlsx\",output_file=\"car_problems_multilingual.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f19b7",
   "metadata": {},
   "source": [
    "## 🤖 Step 2: Generate OpenAI Embeddings\n",
    "\n",
    "This cell processes each document and generates vector embeddings:\n",
    "\n",
    "### Process Flow:\n",
    "1. 📖 **Load documents** from the JSON file\n",
    "2. 🔄 **For each document**:\n",
    "   - Extract the `fault` field as the text to embed\n",
    "   - 🧮 Call OpenAI's embedding API to generate a vector representation\n",
    "   - 📊 Add the embedding vector to the document\n",
    "   - ⏱️ Sleep for 1 second to respect rate limits\n",
    "3. ✅ **Track progress** and count vectorized documents\n",
    "\n",
    "### Why OpenAI Embeddings?\n",
    "- 🌍 **Multilingual support**: Works well with major languages\n",
    "- 📐 **High-quality vectors**: text-embedding-3-large produces 3072-dimensional embeddings\n",
    "- 🔄 **Consistency**: Same model can be used for both indexing and search queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a696c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open('car_problems_multilingual.json', 'r', encoding='utf-8') as f:\n",
    "    cars = json.load(f)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for car in cars:\n",
    "\n",
    "    text_to_embed = car['fault']\n",
    "\n",
    "    response = await openai.embeddings.create(\n",
    "        input=text_to_embed,\n",
    "        model=open_ai_embedding_model\n",
    "    )    \n",
    "\n",
    "    car['vector'] = response.data[0].embedding\n",
    "\n",
    "    documents.append(car)\n",
    "\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "print(f\"{len(documents)} documents vectorized\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bf679",
   "metadata": {},
   "source": [
    "## 🔍 Step 3: Upload Documents to Azure AI Search\n",
    "\n",
    "Upload the vectorized documents to the Azure Cognitive Search index:\n",
    "- 📤 **Batch upload**: All documents with their embeddings are uploaded at once\n",
    "- ✅ **Success verification**: Confirms the upload completed successfully\n",
    "- 🔍 **Index**: Documents are added to the `multi_language_openai` search index\n",
    "- ⚠️ **Error handling**: Catches and displays any upload errors\n",
    "\n",
    "Once uploaded, these documents can be searched using:\n",
    "- 📝 **Keyword search**: Traditional text-based search\n",
    "- 🧮 **Vector search**: Semantic similarity search using embeddings\n",
    "- 🔀 **Hybrid search**: Combination of both approaches for best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = await search_client.upload_documents(cars)\n",
    "    print(\"Upload of new document succeeded: {}\".format(result[0].succeeded))\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
